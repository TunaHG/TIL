# Data Structure

## Array vs LinkedList

> 논리적 저장순서와 물리적 저장순서가 일치하면 Array, 일치하지 않으면 LinkedList
>
> 삽입, 삭제연산에 대해서는 둘 다 $O(n)$의 시간복잡도, Search에 대해서는 Array는 $O(1)$, LinkedList는 $O(n)$의 시간복잡도

### Array

Array는 **논리적 저장순서와 물리적 저장순서가 일치**한다.
따라서, Index로 해당 원소에 접근할 수 있다. 찾고자 하는 원소의 Index값을 알고 있으면 $O(1)$에 해당 원소로 접근할 수 있다.
즉, Random access가 가능하다는 장점이 있다.

하지만 삭제의 과정에서는 해당 원소에 접근하여 작업을 완료한 뒤($O(1)$), 삭제한 원소보다 큰 Index를 갖는 원소들을 shift해줘야 하는 비용이 발생하고 이 경우의 시간 복잡도는 $O(n)$이다. (어느 원소를 삭제 했을 때 빈 공간이 생겨 배열의 연속적인 특징이 깨지기 때문에 shift해줘야함)
Array 자료구조에서 삭제 기능에 대한 Time Complexity의 Worst case는 $O(n)$이다.

삽입의 과정 또한 삭제의 과정과 동일하다. 만약 첫 번째 자리에 새로운 원소를 추가하고자 한다면 모든 원소들의 Index를 1씩 shift 해줘야 하므로 이 경우도 $O(n)$의 시간복잡도를 가진다.

### LinkedList

LinkedList는 **각각의 원소들이 자기 자신 다음에 어떤 원소인지만을 기억**하고 있다.
따라서 이 부분만 다른 값으로 바꿔주면 삭제와 삽입을 $O(1)$만에 해결할 수 있다.

하지만 LinkedList의 문제점은 원하는 위치에 삽입하고자 하면 원하는 위치를 찾는 과정에 있어서 첫 번째 원소부터 다 확인해봐야 한다는 것이다.
Array와는 달리 논리적 저장순서와 물리적 저장순서가 일치하지 않기 때문이다.
일단 삽입하고 정렬하는 것과 마찬가지가 된다. 이 과정때문에 특정 원소를 삭제 또는 추가하고자 했을 때 그 원소를 찾기 위해서 $O(n)$의 시간이 추가적으로 발생하게 된다.

결국 LinkedList는 Search에도 $O(n)$의 시간복잡도를 가지고, 삽입, 삭제에 대해서도 $O(n)$의 시간 복잡도를 가진다.
하지만 LinkedList는 Tree 구조의 근간이 되는 자료구조이며, Tree에서 사용되었을 때 유용성이 드러나기 때문에 학습한다.

## Stack & Queue

### Stack

선형 자료구조의 일종, **LIFO (Last In First Out)**, 나중에 들어간 원소가 먼저 나오는 특징

### Queue

선형 자료구조의 일종, **FIFO (First In First Out)**, 먼저 들어간 원소가 먼저 나오는 특징
*Java Collection에서 Queue는 Interface*이다. 이를 구현하고 있는 Priority Queue를 사용할 수 있다.

## Tree

비선형 자료구조, **계층적 관계(Hierarchical Relationship)를 표현하는 자료구조**
무엇인가를 저장하고 꺼내야 한다기 보다는 표현에 집중한 자료구조

**Tree의 구성요소**

* **Node (노드)** : Tree를 구성하고 있는 각각의 요소
* **Edge (간선)** : Tree를 구성하기 위해 Node와 Node를 연결하는 선
* **Root Node (루트 노드)** : Tree 구조에서 최상위에 있는 Node
* **Terminal Node (= Leaf Node, 단말 노드)** : 하위에 다른 Node가 연결되어 있지 않은 Node
* **Internal Node (내부 노드, 비단말 노드)** : 단말 Node를 제외한 모든 노드로 루트 노드도 포함

### Binary Tree

이진 트리
루트 노드를 중심으로 두 개의 서브 트리로 나뉨. 또한 나뉘어진 두 서브 트리도 모두 이진 트리어야 함
공집합도 이진트리, 노드가 하나 뿐인 것도 이진 트리

**각 층별로 숫자를 매겨서 이를 트리의 Level**이라고 함
Level의 값은 0부터 시작하고 (루트노드의 레벨이 0), **트리의 최고레벨을 가리켜 해당 트리의 높이(Height)**라고 함

* **Perfect Binary Tree**
  포화 이진 트리
  모든 레벨이 꽉 찬 이진 트리
* **Complete Binary Tree**
  완전 이진 트리
  위에서 아래로, 왼쪽에서 오른쪽으로 순서대로 차곡차곡 채워진 이진 트리
* **Full Binary Tree**
  정 이진 트리
  모든 노드가 0개 혹은 2개의 자식 노드만을 가지는 이진 트리

배열로 구성된 Binary Tree는 노드의 개수가 n개이고 root가 0이 아닌 1에서 시작할 때,
i 번째 노드에 대해서 parent(i) = i/2, left_child(i) = 2i, right_child(i) = 2i + 1의 index값을 가진다.

#### BST

> Binary Search Tree

효율적인 탐색을 위한 저장방법
이진 탐색 트리는 이진 트리의 일종으로 데이터를 저장하는 규칙이 있다.
그 규칙은 특정 데이터의 위치를 찾는데 사용할 수 있다.

**규칙**

1. 이진 탐색 트리의 노드에 저장된 키는 유일하다.
2. 부모의 키가 왼쪽 자식 노드의 키보다 크다.
3. 부모의 키가 오른쪽 자식 노드의 키보다 작다.
4. 왼쪽과 오른쪽 서브트리도 이진 탐색 트리이다.

이진 탐색 트리의 탐색 연산은 $O(\log n)$의 시간복잡도를 가진다. 트리의 높이만큼의 시간복잡도를 가지는데, 트리의 높이가 하나씩 높아질수록 추가할 수 있는 노드의 수가 두 배씩 증가하기 때문이다.
하지만 이러한 이진 탐색 트리는 Skewed Tree(편향 트리)가 될 수 있다. 저장 순서에 따라 계속 한 쪽으로만 노드가 추가되는 경우가 발생하기 때문이다.
이럴 경우 성능에 영향을 미치게 되며, 탐색의 worst case가 되어 시간복잡도는 $O(n)$이 된다.

배열보다 많은 메모리를 사용하여 데이터를 저장했지만 탐색에 필요한 시간복잡도가 같게 되는 비효율적인 상황이 발생한다.
이를 해결하기 위해 `Rebalancing` 기법이 등장하였다. 균형을 잡기 위한 트리 구조의 재조정을 의미한다.
이 기법을 구현한 트리에는 여러 종류가 존재하는데 그 중 하나가 이후 살펴볼 Red-Black Tree이다.

### Binary Heap

자료구조의 일종으로 Tree형식을 하고 있으며, Tree중에서도 배열에 기반한 Complete Binary Tree이다.
배열에 Tree의 값들을 넣어줄 때 0번째는 건너뛰고 1번째 Index부터 루트노드가 시작된다. 이는 노드의 고유번호 값과 배열의 Index를 일치시켜 혼동을 줄이기 위함이다.

Heap에는 Max heap(최대힙)과 min heap(최소 힙)이 있다.

* **Max heap**
  각 노드의 값이 해당 children의 값보다 크거나 같은 Complete Binary Tree를 말한다.
  *Root node에 있는 값이 제일 크다.* 그렇기에 최대값을 찾는데 소요되는 연산의 시간복잡도가 $O(1)$이다.
  그리고 Complete Binary Tree이기 때문에 배열을 사용하여 효율적으로 관리할 수있다.
  Heap 구조를 유지하기 위해서는 제거된 루트노드를 대체할 다른 노드가 필요하다. 여기서 heap은 맨 마지막 노드를 루트 노드로 대체시킨 후, 다시 heapify 과정을 거쳐 heap 구조를 유지한다. 이 경우 결국 $O(\log n)$의 시간복잡도로 최대값 또는 최소값에 접근할 수 있다.
* **min heap**
  Max heap의 반대이다.
  각 노드의 값이 해당 children의 값보다 작거나 같은 Complete Binary Tree

### RBT

> Red-Black Tree

BST를 기반으로 하는 트리 형식의 자료구조
RBT에 데이터를 저장하게 되면 Search, Insert, Delete 연산 모두 $O(\log n)$의 시간복잡도가 소요된다.
*동일한 노드의 개수일 때 depth를 최소화하여 시간 복잡도를 줄이는 것이 핵심 아이디어*이다.
동일한 노드의 개수일 때 depth가 최소가 되는 경우는 tree가 Complete Binary Tree인 경우이다.

**RBT의 정의** 
RBT는 다음의 성질들을 만족하는 BST이다.

* 각 노드는 `Red` or `Black` 이라는 색깔을 가진다.
* Root node의 색깔은 `Black`이다.
* 각 Leaf node의 색깔은 `Black`이다.
* 어떤 노드의 색깔이 `Red`라면 두 개의 Children의 색깔은 모두 `Black`이다.
* 각 노드에 대해서 노드로부터 descendant leaves 까지의 단순 경로는 모두 같은 수의 Black nodes를 포함하고 있다.
  이를 해당 노드의 Black-Height라고한다.
  *Black-Height: 노드 X로부터 X를 포함하지 않은 Leaf node까지의 simple path상에 잇는 black nodes의 개수*

**RBT의 특징**

* Binary Search Tree이므로 BST의 특징을 모두 가진다.
* Root node부터 Leaf node까지의 모든 경로 중 최소 경로와 최대 경로의 크기 비율은 2보다 크기 않다.
  이러한 상태를 `balanced`라고한다.
* node의 child가 없을 경우 child를 가리키는 포인터는 `NIL` 값을 저장한다. 이러한 `NIL` 들을 Leaf node로 간주한다.

RBT는 BST의 삽입, 삭제 연산 과정에서 발생할 수 있는 문제점을 해결하기 위해 만들어진 자료구조이다.

* **삽입**
  우선  BST의 특성을 유지하면서 삽입을 하며, 삽입된 노드의 색깔을 Red로 지정한다. 이는 Black-Height의 변경을 최소화하기 위함이다.
  삽입 결과 RBT의 특성을 위배할시 노드의 색깔을 조정하고, Black-Height가 위배되었다면 Rotation을 통해 Height를 조정한다.
  이러한 과정을 통해 RBT의 동일한 Height에 존재하는 Internal node들의 Black-Height가 같아지게 되고, 최소경로와 최대 경로의 크기 비율이 2 미만으로 유지된다.
* **삭제**
  삽입과 마찬가지로 BST의 특성을 유지하면서 노드를 삭제한다. 삭제할 노드의 child 개수에 따라 Rotation 방법이 달라지게 된다.
  지워진 노드의 색깔이 Black 이라면 Black-Height가 1 감소한 경로에 Black node가 1개 추가되도록 Rotation하고 노드의 색깔을 조정한다.
  지워진 노드의 색깔이 Red라면 Violation이 발생하지 않으므로 RBT가 그대로 유지된다.

Java Collection에서 ArrayList도 내부적으로 RBT로 이루어져 있고, HashMap에서의 Separate Chaining에서도 사용된다.

## Hash Table

Hash는 내부적으로 배열을 사용하여 데이터를 저장하기 때문에 빠른 검색 속도를 가진다.
특정한 값을 Search하는데 데이터 고유의 Index로 접근하게 되므로 Average case에 대하여 시간복잡도가 $O(1)$이다. (항상 $O(1)$이 아닌 이유는 Collision 때문이다.) 하지만 문제는 이 Index로 저장되는 Key값이 불규칙하다는 것이다.

그래서 특별한 알고리즘을 이용하여 저장할 데이터와 연관된 고유한 숫자를 만들어 낸 뒤 이를 Index로 사용한다.
특정 데이터가 저장되는 Index는 그 데이터만의 고유한 위치이기 때문에, 삽입 연산시 다른 데이터의 사이에 끼어들거나, 삭제 시 다른 데이터로 채울 필요가 없으므로 연산에서 추가적인 비용이 없도록 만들어진 구조이다.

### Hash Function

특별한 알고리즘을 `Hash method` 혹은 `Hash Function`이라고 하고 이 메소드에 의해 반환된 데이터의 고유 숫자 값을 `Hashcode`라고 한다.
저장되는 값들의 key값을 hash function을 통해서 작은 범위의 값들로 바꿔준다.

하지만 어설픈 hash function을 통해서 key값들을 결정한다면 동일한 값이 도출될 수가 있다. 이렇게 되면 동일한 key값에 복수 개의 데이터가 하나의 테이블에 존재할 수 있게 되는 것인데 이를 Collision이라고 한다.
*Collision: 서로 다른 두 개의 키가 같은 인덱스로 hashing되면 같은 곳에 저장할 수 없게 된다.*

**좋은 hash function의 조건**
일반적으로 좋은 hash function은 키의 일부분을 참조하여 해쉬 값을 만들지 않고 **키 전체를 참조하여 해쉬 값을 만들어 낸다**. 하지만 좋은 hash function은 키가 어떤 특성을 가지고 있느냐에 따라서 달라지게 된다.
hash function을 무조건 1:1로 만드는 것보다 **Collision을 최소화하는 방향으로 설계하고 발생하는 Collision에 어떻게 대비할 것인가가 더 중요**하다.
1:1 대응이 되도록 만드는 것이 거의 불가능하기도 하지만 그런 hash function을 만들어봤자 그건 array와 다를바 없고 메모리를 너무 차지하게 된다.
Collision이 많아질수록 Search에 필요한 시간 복잡도가 $O(1)$에서 $O(n)$에 가까워진다. 좋은 hash function을 선택하는 것이 성능향상에 필수적인 것이다.
따라서 hashing된 Index에 이미 다른 값이 들어있다면 새 데이터를 저장할 다른 위치를 찾은 뒤에야 저장할 수 있는 것이다. 따라서 충돌 해결은 필수이며 그 방법들에 대해 알아본다.

**Resolve Conflict**

1. **Open Address 방식 (개방주소법)**
   해시 충돌이 발생하면, 다른 해시 버킷에 해당 자료를 삽입하는 방식이다.
   버킷이란 바구니와 같은 개념으로 데이터를 저장하기 위한 공간을 의미한다.
   공개 주소 방식이라고도 불리는 이 알고리즘은 Collision이 발생하면 데이터를 저장할 장소를 찾아 헤맨다. worst case의 경우 비어있는 버킷을 찾지 못하고 탐색을 시작한 위치까지 되돌아 올 수 있다. 이 과정에서도 여러 방법들이 존재한다.

   * **Linear Probing**
      순차적으로 탐색하며 비어있는 버킷을 찾을 때까지 계속 진행된다.
   * **Quadratic Probing**
     2차 함수를 이용해 탐색할 위치를 찾는다.
   * **Double Hashing Probing**
     하나의 해쉬 함수에서 충돌이 발생하면 2차 해쉬 함수를 이용해 새로운 주소를 할당한다.
     위 두 가지 방법에 비해 많은 연산량을 요구한다.

2. **Separate Chaining 방식 (분리연결법)**
   일반적으로 개방주소법은 분리연결법보다 느리다.
   개방주소법의 경우 해시 버킷을 채운 밀도가 높아질수록 worst case의 발생 빈도가 더 높아지기 때문이다.
   반면 분리연결법의 경우 해시 충돌이 잘 발생하지 않도록 보조 해시 함수를 통해 조정할 수 있다면 worst case에 가까워 지는 빈도를 줄일 수 있다.
   Java 7 에서는 분리연결법을 사용하여 HashMap을 구현하고 있다. 분리연결법 방식으로는 두 가지 구현방식이 있다.

   * **연결 리스트를 사용하는 방식(LinkedList)**
     각각의 버킷들을 연결리스트로 만들어 Collision이 발생하면 해당 버킷의 List에 추가하는 방식이다.
     연결 리스트의 특징을 그대로 이어받아 삭제 또는 삽입이 간단하다. 하지만 단점도 그대로 물려받아 작은 데이터들을 저장할 때 연결 리스트 자체의 오버헤드가 부담이 된다.
     다른 특징으로는 버킷을 계속해서 사용하는 개방주소법 방식에 비해 테이블의 확장을 늦출 수 있다.
   * **Tree를 사용하는 방식(Red-Black Tree)**
     기본적인 알고리즘은 분리연결법 방식과 동일하며 연결 리스트 대신 트리를 사용하는 방식이다.
     연결리스트와 트리중 어떤 것을 사용할 것인가에 대한 기준은 하나의 해시 버킷에 할당한 key-value 쌍의 개수이다. 데이터의 개수가 적다면 연결 리스트를 사용하는 것이 맞다. 트리는 기본적으로 메모리 사용량이 많기 때문이다. 데이터 개수가 적을 때 worst case를 살펴보면 트리와 연결 리스트의 성능 상 차이가 거의 없다. 따라서 메모리 측면을 봤을 때 데이터 개수가 적을 때는 연결리스트를 사용한다.

   데이터가 적다는 것은 key-value 쌍의 개수가 6개, 8개를 기준으로 결정한다. 연결리스트의 기준과 트리의 기준을 6과 8로 잡은 것은 변경하는데 소요되는 비용을 줄이기 위함이다.

   해시 버킷에 6개의 key-value 쌍이 들어있다고 가정한다. 이후 하나의 값이 추가되었을 때, 만약 기준이 6과 7이라면 자료구조를 연결리스트에서 트리로 변경해야 한다. 그러다 바로 하나의 값이 삭제된다면 다시 트리에서 연결 리스트로 자료구조를 변경해야 한다.
   각각 자료구조로 넘어가는 기준이 1이라면 Switching 비용이 너무 많이 필요하게 되는것이다. 그래서 2라는 여유를 남겨두고 기준을 잡아준 것이다.
   따라서 6에서 7로 증가했을때는 연결리스트의 자료구조를 취하고 있을 것이고, 8에서 7로 감소했을 때는 트리의 자료구조를 취하고 있을 것이다.

**Open Address vs Separate Chaining**

두 방식 모두 worst case에서 $O(N)$의 시간복잡도를 가진다.
하지만 개방주소법은 연속된 공간에 데이터를 저장하기 때문에 분리연결법에 비해 캐시 효율이 높다. 따라서 데이터의 개수가 충분히 적다면 개방주소법이 분리연결법보다 성능이 더 좋다.
또한 분리연결법에 비해 개방주소법은 버킷을 계속해서 사용한다. 따라서 분리연결법은 테이블의 확장을 늦출수 있다.

**보조 해시 함수**

보조 해시 함수(Supplement Hash Function)의 목적은 key의 해시 값을 변형하여 해시 충돌 가능성을 줄이는 것이다.
분리연결법을 사용할 때 함께 사용되며 보조 해시 함수로 Worst case에 가까워지는 경우를 줄일 수 있다.

### 해시 버킷 동적 확장 (Resize)

해시 버킷의 수가 적다면 메모리 사용을 아낄 수 있지만 해시 충돌로 인해 성능 상 손실이 발생한다.
그래서 HashMap은 key-value 쌍의 개수가 일정 개수 이상이 되면 해시 버킷의 개수를 두 배로 늘린다. 이렇게 늘리면 해시 충돌로 인한 성능 손실 문제를 어느 정도 해결할 수 있다. 두 배로 확장하는 임계점은 현재 데이터 개수가 해시 버킷 개수의 75%가 될 때이다. 0.75라는 숫자는 load factor라고 불린다.

### 참고

https://d2.naver.com/helloworld/831311

## Graph

Graph는 정점과 간선의 집합이다. (Tree 또한 Graph이며, 그 중 사이클이 허용되지 않는 Graph를 말한다.)

**Graph 관련 용어**

* **Undirected Graph, Directed Graph (Digraph)**
  정점과 간선의 연결관계에 있어서 방향성이 없는 그래프를 Undirected Graph
  간선에 방향성이 포함되어 있는 그래프를 Directed Graph라고 한다.
* **Degree**
  Undirected Graph에서 각 정점(Vertex)에 연결된 간선(Edge)의 개수를 Degree라고 한다.
  Directed Graph에서는 간선에 방향성이 존재하기 때문에 Degree가 두 개로 나뉘게 된다. 각 정점으로 부터 나가는 간선의 개수를 Outdegree, 들어오는 간선의 개수를 Indegree라고 한다.
* **Weight Graph(가중치 그래프), Sub Graph(부분 그래프)**
  가중치 그래프란 간선에 가중치 정보를 두어서 구성한 그래프를 의미한다. 반대의 개념으로 모든 간선의 가중치가 동일한 비가중치 그래프가 존재한다.
  부분 그래프는 부분 집합과 유사한 개념으로, 본래의 그래프의 일부 정점 및 간선으로 이루어진 그래프를 의미한다.

**Graph를 구현하는 방법**

* **Adjacent matrix (인접 행렬)**
  정방 행렬을 사용하는 방법
  해당하는 위치의 value 값을 통해서 vertex 간의 연결 관계를 $O(1)$로 파악할 수 있다. Edge 개수와는 무관하게 $V^2$의 공간복잡도를 가진다.
  Dense Graph를 표현할 때 적절한 방법이다.
* **Adjacent list (인접 리스트)**
  연결 리스트를 사용하는 방법
  vertex의 adjacent list를 확인해봐야 하므로 vertex간 연결되어있는지 확인하는데 오래 걸린다. 공간복잡도는 $O(E + V)$이다.
  Sparse Graph를 표현하는데 적절한 방법이다.

### Graph 탐색

정점의 구성 뿐만 아니라 간선의 연결에도 규칙이 존재하지 않기 때문에 탐색이 복잡하다.
따라서, 그래프의 모든 정점을 탐색하기 위한 방법은 다음의 두 가지 알고리즘을 기반으로 한다.

* **깊이 우선 탐색 (DFS, Depth First Search)**
  그래프 상에 존재하는 임의의 한 정점으로부터 연결되어 있는 한 정점으로만 나아간다라는 방법을 우선으로 탐색한다. 일단 연결된 정점으로 탐색하는 것이다.
  연결할 수 있는 정점이 있을 때까지 계속 연결하다가 더이상 연결되지 않은 정점이 없으면 바로 그 전 단계의 정점으로 돌아가서 연결할 수 있는 정점이 있는지 살펴봐야 할 것이다. 갔던 길을 되돌아 오는 상황이 존재하는 미로찾기처럼 구성하면 되는 것이다.
  사용하는 자료구조는 Stack이다. 시간복잡도는 $O(V + E)$로 vertex의 개수 + edge의 개수이다.
* **너비 우선 탐색 (BFS, Breadth First Search)**
  그래프 상에 존재하는 임의의 한 정점으로부터 연결되어 있는 모든 정점으로 나아간다. Tree에서 Level Order Traversal 형식으로 진행되는 것이다.
  사용하는 자료구조는 Queue이다. 연락을 취할 정점의 순서를 기록하기 위한 것이다. 우선, 탐색을 시작하는 정점을 Queue에 넣는다(Enqueue). 그리고 Dequeue를 하면서 Dequeue하는 정점과 간선으로 연결되어 있는 정점들을 Enqueue한다. 즉 vertex를 방문한 순서대로 queue에 저장하는 방법을 사용하는 것이다. 시간복잡도는 $O(V + E)$로 vertex의 개수 + edge의 개수이다. BFS로 구한 경로는 최단 경로이다.

### Minimum Spanning Tree

그래프 G의 Spanning Tree중 Edge weight의 합이 최소인 spanning tree를 말한다.
spanning tree란, 그래프 G의 모든 vertex가 cycle이 없이 연결된 형태를 말한다.

#### Kruskal Algorithm

초기화 작업으로 edge 없이 vertex들만으로 그래프를 구성한다. 그리고 weight가 가장 작은 edge부터 검토한다. 이를 위해 edge set을 non-decreasing으로 sorting해야 한다. 그리고 가장 작은 weight에 해당하는 edge를 추가하는데 추가할 때 그래프에 cycle이 생기지 않는 경우에만 추가한다. spanning tree가 완성되면 모든 vertex들이 연결된 상태로 종료가 되고 완성될 수 없는 그래프에 대해서는 모든 edge에 대해 판단이 이루어지면 종료된다.

**Cycle 생성 여부 판단**

그래프의 각 vertex에 set-id를 추가적으로 부여한다. 그리고 초기화 과정에서 모두 1-n까지의 값으로 각각의 vertex들을 초기화한다.
여기서 0은 어떠한 edge와도 연결되지 않았음을 의미하게 된다. 그리고 연결할 때마다 set-id를 하나로 통일시키는데 값이 동일한 set-id 개수가 많은 set-id값으로 통일시킨다.

**시간복잡도**

Edge의 weight를 기준으로 sorting하는 것은 $O(E \log E)$
Cycle 생성 여부를 검사하고 set-id를 통일하는 것은 $O(E + V \log V)$ 전체 시간 복잡도는 $O(E \log E)$

#### Prim Algorithm

초기화 과정에서 한 개의 vertex로 이루어진 초기 그래프 A를 구현한다. 이후 그래프 A 내부에 있는 vertex로부터 외부에 있는 vertex 사이의 edge를 연결하는데, 그 중 가장 작은 weight의 edge를 통해 연결되는 vertex를 추가한다. 어떤 vertex건 간에 상관없이 edge의 weight를 기준으로 연결하는 것이다. 이렇게 연결된 vertex는 그래프 A에 포함된다. 위 과정을 반복하고 모든 vertex들이 연결되면 종료한다.

시간복잡도는 $O(E \log V)$이다.